{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコアリングフェーズにおけるデータ処理（解決編）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前編にて、スコアリングデータのone-hotエンコーディング後に、以下の問題が生じる得ることを確認しました。<br>\n",
    "- モデルデータにないカラムが生成される可能性\n",
    "- モデルデータにあったカラムが消える可能性\n",
    "- データ型の違いが理由で上記を生じさせてしまう可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そこでこの問題が生じないよう、コードを補強していくことにしましょう。前提として、私達はどのデータが連続変数で、どのデータがカテゴリ変数かは事前に把握しているとします。そして今回のカテゴリ変数は<b>Dependents, Gender, Married, Education, Self_Employed, Property_Areaの６変数</b>とします。最初の補強は、フラットファイルを読み込む段階で<b>カテゴリ変数をobject型として明記して読み込むこと</b>です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sample data: Loan screening data for classification \n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/av_loan_u6lujuX_CVtuZ9i.csv',\n",
    "                 header=0,\n",
    "                 dtype={'Dependents':object,\n",
    "                        'Gender':object,\n",
    "                        'Married':object,\n",
    "                        'Education':object,\n",
    "                        'Self_Employed':object,\n",
    "                        'Property_Area':object})\n",
    "X  = df.iloc[:,:-1]            # 最終列以前を特徴量\n",
    "ID = X.iloc[:,[0]]             # 第0列はPK（Loan_ID）なのでIDとしてセット\n",
    "X  = X.drop('Loan_ID', axis=1) # Loan_IDは特徴ベクトルから削除\n",
    "y  = df.iloc[:,-1]             # 最終列を正解データ\n",
    "\n",
    "# check the shape\n",
    "print('---------------------------------')\n",
    "print('Raw shape: (%i,%i)' %df.shape)\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('---------------------------------')\n",
    "print(X.dtypes)\n",
    "\n",
    "# ローン審査でNOとなったサンプルを1（正例）として変換\n",
    "class_mapping = {'N':1, 'Y':0}\n",
    "y = y.map(class_mapping)\n",
    "print('---------------------------------')\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続けて、モデリング段階のone-hotエンコーディングを行います。ここに変更はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = ['Dependents',\n",
    "               'Gender',\n",
    "               'Married',\n",
    "               'Education',\n",
    "               'Self_Employed',\n",
    "               'Property_Area']\n",
    "\n",
    "X_ohe = pd.get_dummies(X,\n",
    "                       dummy_na=True,\n",
    "                       columns=ohe_columns)\n",
    "\n",
    "print('X_ohe shape:(%i,%i)' % X_ohe.shape)\n",
    "X_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続けて、連続変数の欠損を平均値で置き換えます。ここも変更はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_ohe)\n",
    "\n",
    "X_ohe_columns = X_ohe.columns.values\n",
    "X_ohe = pd.DataFrame(imp.transform(X_ohe), columns=X_ohe_columns)\n",
    "\n",
    "X_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、RFEによる特徴量選択を実施します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "selector = RFE(RandomForestClassifier(random_state=1),\n",
    "               n_features_to_select=10,\n",
    "               step=.05)\n",
    "\n",
    "selector.fit(X_ohe,y)\n",
    "\n",
    "X_fin = X_ohe.loc[:, X_ohe_columns[selector.support_]]\n",
    "print('X_fin shape:(%i,%i)' % X_fin.shape)\n",
    "X_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上でモデリング段階の処理が終わり、<br><b>ここからがテストデータを読み込みとなります。<br>ここでもカテゴリ変数の明示的な指定をしましょう。</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import sample data\n",
    "# Loan screening data for classification \n",
    "df_s = pd.read_csv('./data/av_loan_test_Y3wMUE5_7gLdaTN.csv',\n",
    "                   header=0,\n",
    "                   dtype={'Dependents':object,\n",
    "                          'Gender':object,\n",
    "                          'Married':object,\n",
    "                          'Education':object,\n",
    "                          'Self_Employed':object,\n",
    "                          'Property_Area':object})\n",
    "ID_s = df_s.iloc[:,[0]]            # 第0列はPK（Loan_ID）なのでIDとしてセット\n",
    "X_s  = df_s.drop('Loan_ID',axis=1) # Loan_IDは特徴ベクトルから削除\n",
    "\n",
    "# check the shape\n",
    "print('---------------------------------')\n",
    "print('Raw shape: (%i,%i)' %df_s.shape)\n",
    "print('X shape: (%i,%i)' %X_s.shape)\n",
    "print('---------------------------------')\n",
    "print(X_s.dtypes)\n",
    "ID_s.join(X_s).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ変数をきちんとデータ型でも揃えた状態で、one-hotエンコーディングを実施します。<br>Dependentsに見られた不整合が消えています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s = pd.get_dummies(X_s,\n",
    "                         dummy_na=True,\n",
    "                         columns=ohe_columns)\n",
    "print('X_ohe_s shape:(%i,%i)' % X_ohe_s.shape)\n",
    "X_ohe_s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアリングのone-hotエンコーディングを終えたので、<br>この時点の特徴量リストをモデリング時とスコアリング時で再度比較してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_model = set(X_ohe.columns.values)\n",
    "cols_score = set(X_ohe_s.columns.values)\n",
    "\n",
    "# モデルにはあったがスコアにはないデータ項目\n",
    "diff1 = cols_model - cols_score\n",
    "print('モデルのみに存在する項目: %s' % diff1)\n",
    "\n",
    "# スコアにはあるがモデルになかったデータ項目\n",
    "diff2 = cols_score - cols_model\n",
    "print('スコアのみに存在する項目: %s' % diff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ型の違いによる不一致は消え、以下の違いだけが残りました。\n",
    "- Dependents_3+はスコアリングデータには存在しない\n",
    "- Gender_Unknownはスコアリングデータで新たに登場した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "後者はモデリング時点にないカラムなので削除する他ありません。前者はモデル時点の再現のためデータ項目として再登場させなくてはいけません。それを実現する一つの方法がデータフレームを縦に結合するconcat処理です。一旦サンプルデータからはなれ、concatの基本動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラム構成が同じデータフレームの結合\n",
    "df1 = pd.DataFrame([[1,2,3]], columns=['c1','c2','c3'])\n",
    "df2 = pd.DataFrame([[3,2,1]], columns=['c1','c2','c3'])\n",
    "df_all = pd.concat([df1, df2])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラム構成が異なるデータフレームの結合\n",
    "df3 = pd.DataFrame([[0,1,2,3]],\n",
    "                   columns=['c0','c1','c3','c4'])\n",
    "df_all = pd.concat([df_all, df3])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のc0とc4は、元々あったデータフレーム（df_all）には存在しなかった項目という点で、スコアリングデータに初めて登場した項目と言えます。一方、c2はモデリングデータにはあったがスコアリングデータでは登場しなかったデータ項目となります。よって対応は、①c0とc4はドロップ、②c2はゼロ補完が妥当と結論されるものです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではサンプルデータに戻ります。<br>モデリング時点のone-hotエンコーディング処理後のカラム構成は、X_ohe_columnsでした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_ohe_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このカラム構成だけを持った（データ部分は持たない）データフレームを作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols_m = pd.DataFrame(None,\n",
    "                         columns=X_ohe_columns,\n",
    "                         dtype=float)\n",
    "df_cols_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記データフレームに対して、スコアリング時点のone-hotエンコーディング後のデータを縦に結合します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s2 = pd.concat([df_cols_m, X_ohe_s])\n",
    "X_ohe_s2.head()\n",
    "print(X_ohe_s2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、スコアリングデータのみに登場するデータ項目を削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s2 = X_ohe_s2.drop(list(set(X_ohe_s.columns.values)-set(X_ohe.columns.values)),\n",
    "              axis=1)\n",
    "X_ohe_s2.head()\n",
    "print(X_ohe_s2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、スコアリングでは登場しなかったデータ項目をゼロ埋めします。<br>Depend_3+がNaNから全てゼロとなりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s2.loc[:,list(set(X_ohe.columns.values)-set(X_ohe_s.columns.values))] = \\\n",
    "  X_ohe_s2.loc[:,list(set(X_ohe.columns.values)-set(X_ohe_s.columns.values))].fillna(0, axis=1)\n",
    "X_ohe_s2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、モデリング時点のデータ項目の並び順を明示的に担保します。<br>以下の通り、reindex_axisを使うことで並び順を制御できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame([[1,2,3]], columns=['c1','c2','c3'])\n",
    "display(test)\n",
    "test = test.reindex(['c2','c3','c1'], axis=1)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、モデリング時点のone-hotエンコーディング後の並び順に制御します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s2 = X_ohe_s2.reindex(X_ohe.columns.values, axis=1)\n",
    "X_ohe_s2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で、スコアリング時のone-hotエンコーディングをモデリング時の状況と合致させられました。<br><b>ここまで整合させたことでモデリング時に各変数の平均値を学習させたImputerが適用可能となります。</b><br>連続変数の欠損値も（学習時の）平均値で正しく置き換えられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s3 = pd.DataFrame(imp.transform(X_ohe_s2),\n",
    "                        columns=X_ohe_columns)\n",
    "X_ohe_s3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFEによって選択された変数の位置はsupport_属性から取得できたので、<br>スコアリングデータの特徴量の最終形は以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fin_s = X_ohe_s.loc[:,X_ohe_columns[selector.support_]]\n",
    "print(X_fin_s.shape)\n",
    "X_fin_s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で、スコアリング段階におけるデータの前処理が終了です。<br>このデータを未知のXとして、学習済みモデルに入力すれば予測値を得ることができます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
