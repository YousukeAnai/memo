{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2値分類用のサンプルデータであるBreast Cancerを読み込みます。<br>特徴量が全て数値データで欠損値もないキレイなサンプルデータです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and return the breast cancer wisconsin dataset (classification).\n",
    "# The breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Set dataframe\n",
    "dataset = load_breast_cancer()\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.Series(dataset.target, name='y')\n",
    "\n",
    "# check the shape\n",
    "print('--------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('--------------------------------------------------')\n",
    "print(y.value_counts())\n",
    "print('--------------------------------------------------')\n",
    "print('y=0 means Marignant(悪性),y=1 means Benign(良性):')\n",
    "print('--------------------------------------------------')\n",
    "X.join(y).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k近傍法とロジスティック回帰の呼び出し方を学びましょう。KNNはneighborsというクラスから呼び出しています。ロジスティック回帰は重みベクトルと特徴量の一次線形結合をベースとしたアルゴリズムなので、線形モデルから呼び出せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回帰でも学びましたが、機械学習のアルゴリズムは特徴量ベクトルを標準化するのが普通です。実装は標準化処理とモデル学習（重みの最適化）のプロセスをひとまとめに記述できるパイプラインが便利なため呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "回帰モデルの評価にはR2スコア等がありました。分類モデルの評価の場合、最もわかりやすいものが正解率（Accuracy）です。正解率は予測対象データ（スコアリングデータ）の全件をNとした時、正例を正しく正例と分類できた数TP、負例を正しく負例と分類できた数TFとすると、 以下の数式で表せます。<br><center>Accuracy = (TP + TF) / N</center><br>つまり、正例・負例を問わず正しく分類されたサンプル数の割合です。sklearnでは正解データ（正解ベクトル）と予測データ（予測ベクトル）を与えると、Accuracyを計算してくれる関数が存在します。それを以下で呼び込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分類モデルの評価指標計算のための関数の読込\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下コードの各行の役割を理解できていることを確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Holdout\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,\n",
    "                                                 y,\n",
    "                                                 test_size=0.20,\n",
    "                                                 random_state=1)\n",
    "# set pipelines for two different algorithms\n",
    "pipelines ={\n",
    "    'knn_5': Pipeline([('scl',StandardScaler()),\n",
    "                       ('est',KNeighborsClassifier())]),\n",
    "    'knn_50': Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',KNeighborsClassifier(n_neighbors=50))]),\n",
    "    'logistic': Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',LogisticRegression(random_state=1))])    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn_5はデフォルトのK近傍法のパフォーマンス確認、pipe_knn_50は近傍数を増やしたときの性能確認用です。Kを増やすことで予測性能（正解率）がどのように変化するか考えてみましょう。pipe_logisticはロジスティック回帰の性能確認用です。kNNよりは良いだろうというのが通常の期待です。それでは各パイプラインを学習(fit)させましょう。正常終了すれば終了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the parameters of each algorithms\n",
    "for pipe_name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    print(pipe_name, ': Fitting Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、３つのパイプラインの分類器としての性能（正解率）を比較します。<br>まずpipelineのpredictの出力ベクトルを見て下さい。<br>y_pred in {0,1}で予測ラベルが付与されていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['logistic'].predict(X_train)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は使いませんが、実務では予測ラベルの他に各クラスに分類される予測確率をよく使います。<b>予測確率を出力させたい場合はpredictをpredic_probaに変更するだけです。</b>最初の列はy=0と分類される予測確率、2番目の列はy=1と分類される予測確率です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['logistic'].predict_proba(X_train)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy_scoreは第一引数に正解ラベル、第二引数に予測ラベル（確率ではない）を指定します。<br>今回はpredictで予測ラベルを与えましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = {}\n",
    "for pipe_name, pipeline in pipelines.items():\n",
    "    scores[(pipe_name,'train')] = accuracy_score(y_train, pipeline.predict(X_train))\n",
    "    scores[(pipe_name,'test')] = accuracy_score(y_test, pipeline.predict(X_test))\n",
    "\n",
    "pd.Series(scores).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k近傍法のkを5から50に増やしましたが、性能が落ちてしまいました。多くのデータを見過ぎて平均値予測に近づき過ぎてしまったようです。予測値が無難過ぎてTrainスコアとTestスコアが近いのも特徴です。ロジスティック回帰は、k近傍法より3pt（0.956 to 0.982）程度、改善することを確認できました。ただし、どのように改善するか（しないか）はデータ次第ですので、代表的なアルゴリズムをいつでも試せる準備をしておくことが、プロジェクト進行において大切です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
